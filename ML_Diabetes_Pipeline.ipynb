{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/siddmuns/diabetes-ml-pipeline.git\n",
        "%cd diabetes-ml-pipeline\n",
        "!pip install -q -r requirements.txt"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l\n",
        "# If you need to upload manually, use from google.colab import files; files.upload()"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.makedirs(\"artifacts\", exist_ok=True)\n",
        "os.makedirs(\"mlruns\", exist_ok=True)"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from data_ingestion import preprocess_and_split\n",
        "X_train, X_valid, X_test, y_train, y_valid, y_test, scaler, feature_names = preprocess_and_split(\n",
        "    \"diabetes.csv\", out_dir=\"artifacts\"\n",
        ")"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "mlflow.set_tracking_uri(\"file://\" + \"/content/mlruns\")\n",
        "mlflow.set_experiment(\"Diabetes_Pipeline\")\n",
        "print(\"MLflow tracking URI:\", mlflow.get_tracking_uri())"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tune_and_train import run_optuna, setup_mlflow, retrain_final_and_log\n",
        "import numpy as np\n",
        "\n",
        "# Ensure MLflow is set up\n",
        "setup_mlflow(local_dir=\"mlruns\", experiment_name=\"Diabetes_Pipeline\")\n",
        "\n",
        "# Load pre-saved splits\n",
        "splits = np.load(\"artifacts/splits.npz\", allow_pickle=True)\n",
        "X_train = splits[\"X_train\"]\n",
        "X_valid = splits[\"X_valid\"]\n",
        "X_test = splits[\"X_test\"]\n",
        "y_train = splits[\"y_train\"]\n",
        "y_valid = splits[\"y_valid\"]\n",
        "y_test = splits[\"y_test\"]\n",
        "\n",
        "# Run Optuna hyperparameter search\n",
        "study = run_optuna(X_train, y_train, X_valid, y_valid, n_trials=20)\n",
        "best_params = study.best_trial.params\n",
        "print(\"Optuna best params:\", best_params)\n",
        "\n",
        "# Retrain final model on train+valid\n",
        "X_train_full = np.vstack([X_train, X_valid])\n",
        "y_train_full = np.concatenate([y_train, y_valid])\n",
        "\n",
        "import pandas as pd\n",
        "example_input = pd.DataFrame(\n",
        "    X_train_full[:5],\n",
        "    columns=[f\"feature_{i}\" for i in range(X_train_full.shape[1])]\n",
        ")\n",
        "\n",
        "with mlflow.start_run(run_name=\"Final_Model\") as run:\n",
        "    model, test_acc, test_auc, train_time, model_path = retrain_final_and_log(\n",
        "        X_train_full, y_train_full, X_test, y_test, best_params, artifacts_dir=\"artifacts\"\n",
        "    )\n",
        "    mlflow.log_params(best_params)\n",
        "    mlflow.log_metrics({\n",
        "        \"test_accuracy\": float(test_acc),\n",
        "        \"test_roc_auc\": float(test_auc),\n",
        "        \"train_time_s\": float(train_time)\n",
        "    })\n",
        "    mlflow.sklearn.log_model(\n",
        "        model,\n",
        "        name=\"final_model\",\n",
        "        input_example=example_input\n",
        "    )\n",
        "    run_id = run.info.run_id\n",
        "    print(\"Logged final model, run_id:\", run_id)"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from mlflow import MlflowClient\n",
        "client = MlflowClient()\n",
        "\n",
        "# Skip registry if using file:// backend\n",
        "if not mlflow.get_tracking_uri().startswith(\"file://\"):\n",
        "    try:\n",
        "        model_uri = f\"runs:/{run_id}/final_model\"\n",
        "        client.create_registered_model(\"Diabetes_GB_Model\")\n",
        "        mv = client.create_model_version(\"Diabetes_GB_Model\", model_uri, run_id)\n",
        "        print(\"Registered model version:\", mv.version)\n",
        "    except Exception as e:\n",
        "        print(\"Model registration failed:\", e)\n",
        "else:\n",
        "    print(\"Skipping registry on file:// backend\")"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "joblib.dump(model, \"artifacts/gb_final_model.pkl\")\n",
        "joblib.dump(scaler, \"artifacts/scaler.pkl\")\n",
        "print(\"Saved gb_final_model.pkl and scaler.pkl\")"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from batch_inference import batch_predict\n",
        "out = batch_predict(\"artifacts/gb_final_model.pkl\", \"artifacts/scaler.pkl\", \"diabetes2.csv\", \"artifacts/predictions.csv\")\n",
        "out.head()"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from drift_detection import detect_and_log_drift\n",
        "rpt = detect_and_log_drift(\"diabetes.csv\", \"diabetes2.csv\", out_dir=\"artifacts\")\n",
        "print(rpt)"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from visualize_and_evaluate import make_plots_and_log\n",
        "make_plots_and_log(model, X_test, y_test, feature_names, run_name=\"Final_Plots\")"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}
