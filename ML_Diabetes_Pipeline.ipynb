{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/siddmuns/diabetes-ml-pipeline.git\n",
        "%cd diabetes-ml-pipeline\n",
        "!pip install -q -r requirements.txt"
      ],
      "metadata": {
        "id": "vIWsLJdZ9WLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: if files are in session storage already, ensure they exist:\n",
        "!ls -l\n",
        "# If you need to upload manually, use from google.colab import files; files.upload()"
      ],
      "metadata": {
        "id": "lhuqRw_V_H2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.makedirs(\"artifacts\", exist_ok=True)\n",
        "os.makedirs(\"mlruns\", exist_ok=True)"
      ],
      "metadata": {
        "id": "QieZhLoS_ldr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run the preprocessing script functions directly in notebook\n",
        "from data_ingestion import preprocess_and_split\n",
        "X_train, X_valid, X_test, y_train, y_valid, y_test, scaler, feature_names = preprocess_and_split(\n",
        "    \"diabetes.csv\", out_dir=\"artifacts\"\n",
        ")\n",
        "# Save scaler to artifacts (preprocess already saved scaler.pkl)\n"
      ],
      "metadata": {
        "id": "dNrRrNSy_oEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "mlflow.set_tracking_uri(\"file://\" + \"/content/mlruns\")  # adjust path if needed\n",
        "mlflow.set_experiment(\"Diabetes_Pipeline\")\n",
        "print(\"MLflow tracking URI:\", mlflow.get_tracking_uri())\n"
      ],
      "metadata": {
        "id": "-YwSgwCG_q0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run the combined tune_and_train script\n",
        "from tune_and_train import run_optuna, setup_mlflow\n",
        "import numpy as np\n",
        "\n",
        "# Ensure MLflow is set up\n",
        "setup_mlflow(local_dir=\"mlruns\", experiment_name=\"Diabetes_Pipeline\")\n",
        "\n",
        "# Load splits (already returned above, but tune_and_train main expects loads from artifacts/splits.npz if run as script)\n",
        "import numpy as np\n",
        "splits = np.load(\"artifacts/splits.npz\", allow_pickle=True)\n",
        "X_train = splits[\"X_train\"]\n",
        "X_valid = splits[\"X_valid\"]\n",
        "X_test = splits[\"X_test\"]\n",
        "y_train = splits[\"y_train\"]\n",
        "y_valid = splits[\"y_valid\"]\n",
        "y_test = splits[\"y_test\"]\n",
        "\n",
        "# run optuna\n",
        "study = run_optuna(X_train, y_train, X_valid, y_valid, n_trials=20)\n",
        "best_params = study.best_trial.params\n",
        "print(\"Optuna best params:\", best_params)\n",
        "\n",
        "# retrain final model on train+valid (done by tune_and_train main if run as script)\n",
        "from tune_and_train import retrain_final_and_log\n",
        "X_train_full = np.vstack([X_train, X_valid])\n",
        "y_train_full = np.concatenate([y_train, y_valid])\n",
        "model, test_acc, test_auc, train_time, model_path = retrain_final_and_log(\n",
        "    X_train_full, y_train_full, X_test, y_test, best_params, artifacts_dir=\"artifacts\"\n",
        ")\n",
        "print(\"Final test accuracy:\", test_acc, \"AUC:\", test_auc)\n"
      ],
      "metadata": {
        "id": "Z3wJo2xi_tD6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "from mlflow import MlflowClient\n",
        "import pandas as pd\n",
        "\n",
        "# ⚡ Create example input for MLflow schema inference\n",
        "example_input = pd.DataFrame(\n",
        "    X_train_full[:5],\n",
        "    columns=[f\"feature_{i}\" for i in range(X_train_full.shape[1])]\n",
        ")\n",
        "\n",
        "with mlflow.start_run(run_name=\"Final_Model\") as run:\n",
        "    # Log params and metrics\n",
        "    mlflow.log_params(best_params)\n",
        "    mlflow.log_metrics({\n",
        "        \"test_accuracy\": float(test_acc),\n",
        "        \"test_roc_auc\": float(test_auc)\n",
        "    })\n",
        "\n",
        "    # ⚡ Correct model logging\n",
        "    mlflow.sklearn.log_model(\n",
        "        model,\n",
        "        name=\"final_model\",\n",
        "        input_example=example_input\n",
        "    )\n",
        "\n",
        "    run_id = run.info.run_id\n",
        "    print(\"Logged final model to MLflow, run_id:\", run_id)\n",
        "\n",
        "# Attempt to register model\n",
        "client = MlflowClient()\n",
        "try:\n",
        "    model_uri = f\"runs:/{run_id}/final_model\"\n",
        "    registered = client.create_registered_model(\"Diabetes_GB_Model\")\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "try:\n",
        "    mv = client.create_model_version(\"Diabetes_GB_Model\", model_uri, run.info.run_id)\n",
        "    print(\"Registered model version:\", mv.version)\n",
        "except Exception as e:\n",
        "    print(\"Model registration failed or not supported on local backend:\", e)"
      ],
      "metadata": {
        "id": "6_LsI0Ko_tu-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "joblib.dump(model, \"artifacts/gb_final_model.pkl\")\n",
        "joblib.dump(scaler, \"artifacts/scaler.pkl\")\n",
        "print(\"Saved gb_final_model.pkl and scaler.pkl\")\n"
      ],
      "metadata": {
        "id": "na-BsP08_vao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from batch_inference import batch_predict\n",
        "out = batch_predict(\"artifacts/gb_final_model.pkl\", \"artifacts/scaler.pkl\", \"diabetes2.csv\", \"artifacts/predictions.csv\")\n",
        "out.head()\n"
      ],
      "metadata": {
        "id": "Vc2_3C08_w5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from drift_detection import detect_and_log_drift\n",
        "rpt = detect_and_log_drift(\"diabetes.csv\", \"diabetes2.csv\", out_dir=\"artifacts\")\n",
        "print(rpt)\n"
      ],
      "metadata": {
        "id": "93Y9Mbyg_yN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from visualize_and_evaluate import make_plots_and_log\n",
        "# Need X_test, y_test, feature_names; they were loaded earlier from splits\n",
        "make_plots_and_log(model, X_test, y_test, feature_names, run_name=\"Final_Plots\")\n"
      ],
      "metadata": {
        "id": "DlLdWsgt_zos"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
